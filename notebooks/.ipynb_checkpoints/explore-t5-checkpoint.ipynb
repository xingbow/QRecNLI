{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df332f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(os.path.dirname(os.getcwd()), 'backend')\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_number = 42\n",
    "set_seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201dcc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.dataService import sql2sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2793cee",
   "metadata": {},
   "source": [
    "## Explore T5\n",
    "- https://huggingface.co/t5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfaba83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "# add special tokens\n",
    "# special_tokens = {'bos_token': '<BOS>',\n",
    "#                   'cls_token': '<CSL>',\n",
    "#                   'additional_special_tokens': ['<MY_NEW_TOKEN>', '<ANOTHER_TOKEN>']}\n",
    "# tokenizer.add_special_tokens(special_tokens_dict=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc21974",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = sql2sql.args_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0386f0e",
   "metadata": {},
   "source": [
    "## IMDB sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd65d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n",
      "Loading cached shuffled indices for dataset at /home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-8354e7761f356f2f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.dataset_split): 25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6278"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = sql2sql.ImdbDataset(tokenizer, load_dataset(\"imdb\"), 'train', ['negative</s>', 'positive</s>'], max_len=512)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef4264ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6162"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2548a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.targets[0]: {'input_ids': tensor([[2841,    1,    1,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset.targets[0]: {dataset.targets[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e5666",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46facaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p t5_base_imdb_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5131ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args_dict.update({'output_dir': 't5_base_imdb_sentiment', 'num_train_epochs': 1, 'vocab_file': 'tokenizer_config.json'})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67c0df74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n",
      "Loading cached shuffled indices for dataset at /home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-de8fb117c43e3917.arrow\n",
      "Reusing dataset imdb (/home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n",
      "Loading cached shuffled indices for dataset at /home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-4136b8a3420daa1d.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b25332d524d4e318ae32eaffa123b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = sql2sql.T5FineTuner(args)\n",
    "trainer = pl.Trainer(**train_params)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2092b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save the model this way so next time you can load it using T5ForConditionalGeneration.from_pretrained\n",
    "model.model.save_pretrained('t5_base_imdb_sentiment')\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740f082",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89997960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e564d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n",
      "Loading cached shuffled indices for dataset at /home/xingbo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-de8fb117c43e3917.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = sql2sql.ImdbDataset(tokenizer, load_dataset(\"imdb\"), 'test', ['negative</s>', 'positive</s>'], max_len=512)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3888e031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(loader)\n",
    "batch = next(it)\n",
    "batch[\"source_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e71a3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudamodel = model.model.to('cuda')\n",
    "outs = cudamodel.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f68dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
    "texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['source_ids']]\n",
    "targets = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['target_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb9161c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Okay so there were the odd hole in the plot you could drive a zeppelin through but how well\n",
      "was the emotional stuff handled It would have been so easy to descend into cheesiness but the writer\n",
      "pulled it off The image of the ex female cyberman making crying noises as sheit saw her reflection\n",
      "after regaining her emotions is one that will stay with me forever Thats twice now the monsters have\n",
      "shown a soft side and been presented fleetingly sympathetically the previous being the last Dalek\n",
      "from series one but by Jove its worked Add to that the other exfemale who had been upgraded on the\n",
      "eve of her wedding and Jackie Tyler recognising her husband after she had become cyber and you have\n",
      "a permanent throat lump Keep it up\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Nightscream is a TV Movie so its bound to be pretty dire especially as its a supposed horror\n",
      "film This young girl is haunted by dreams as she arrives in a small town where there was a murder of\n",
      "a woman one year before She is amazed when everyone in the town thinks she looks exactly like the\n",
      "murdered girl The townsfolk are amazed when she keeps entering dream like trances where she reveals\n",
      "accurate details about the murder and murderer because the police got it all wrong apparently\n",
      "Thinking that they are in danger of being found out the murderers there are two of them start to\n",
      "hatch a plan to get rid of her before she gets to the real truth By this time you will have probably\n",
      "fallen asleep and why do the makers of the film have the mistmaking machine on full throttle in the\n",
      "dream sequences\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: If you saw the grudge a another mediocre ghost movie then you should know what to expect\n",
      "just worse a lot worse This Time instead of being in Japan with all English speaking people we are\n",
      "in Spain with all English speaking people It is interesting that not one shot of this movie actually\n",
      "looks like Spain and could have been entirely filmed in a studio back lot Oh and a place with swings\n",
      "cause theres a good 5 mins of footage of swings with no one on them oooohhh how spookyThis one is\n",
      "terrible in every way imaginable The acting by the lameinator mom and dad dont help matters at all\n",
      "Anna Paquin is the only person that delivers a decent performance in the film but I hate Anna Paquin\n",
      "so you can imagine my own private hell viewing this filmThere is one good moment in the movie\n",
      "however when a villain is trying to explain the convoluted plot to Anna Paquins character and she\n",
      "doesnt understand any of it and asks a bunch of stupid questions and he blurts out You IDIOT you\n",
      "have not understood anything lol Well I happen to understand this film is a piece of garbage 0 stars\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: As someone who loves baseball history especially the early 20th century in which Cobb was a\n",
      "main figure along with a ton of colorful characters I was looking forward to seeing this baseball\n",
      "film Well it wasnt a baseball film which was disappointing No it was just a sportswriters account of\n",
      "being with Cobb in the ballplayers later years while the two collaborated on a book Even at that\n",
      "this could have been a more appealing movie than they made itGranted Cobb was anything but a nice\n",
      "guy an extremely talented player but brutal in that he would do anything to beat youand he was\n",
      "viscous intimidating and had a lot of demons to fight He was so hated his own teammates tried to\n",
      "hinder his chances of winning a batting title one year Nonetheless this an overthetop portrayal of\n",
      "the man It makes him into something almost cartoonlike Watching and listening to an old man rant\n",
      "rave and profane for two hours is entertainment No it isnt Some day Id love to see a real biopic of\n",
      "Cobb showing him in his ballplaying days and if they want to portray him as an evil guy so be it but\n",
      "the way they did it here with just a bitter blasphemous old man making an ass of himself in front of\n",
      "a reporter is not fun to watch\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Hulk Hogan stars as a champion wrestler A real acting stretch named Rip who is forced to\n",
      "defend his honor his title and his girlfriend from a greedy corporation that wanted him to sign for\n",
      "their network Because wrestling sells however when Rip declines the network gets a circuit fighting\n",
      "championship called and im totally serious Battle of the tough guys whos champion Zeus Played by\n",
      "Tiny Lister Jr maybe the deadliest man alive Rip refuses to fight until his brother is attacked and\n",
      "put in a hospital No Holds Barred is pretty much what I expected from Vince McMahon production\n",
      "starring the least versatile actor in the action genre Hogan it is basically lots of unintentional\n",
      "humor tons of awkward sequences a couple okay action sequences and tons of stupidity In other words\n",
      "its not unlike wrestling itself so I give it a fair rating mainly because anyone renting this knows\n",
      "what theyre getting The movie is cheap but well made enough for what it is and really wrestling fans\n",
      "will probably enjoy this I myself found this to be ultimately hilarious Theyre are moments of such\n",
      "absurdity that you only chuckle to yourself Such as the way Hogan jumps 20 feet in the air after\n",
      "being stuck in a limo how he forces a guy to crap himself and of course the way Hogan recites from\n",
      "his cuecard IEIm not going to be around when this check clears No Holds Barred is a lot of fun true\n",
      "though its mainly because of how ridiculous it is Fans of camp should really enjoy this clever\n",
      "clinker* * out of 4Fair\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: THE STUDENT NURSES is not a typical sexploitation movie Sure the nudity and sexual openness\n",
      "is there but its not all for laughs Stephanie Rothman scripted a socially compelling wellwritten\n",
      "tits & ass movie which confronts the topics of racism socioeconomic inequalities rape abortion\n",
      "medical ethics public health issues human rights the Vietnam war free love LSD and drug\n",
      "experimentation Four sexy college roommates are taking their nursing internships at the same time\n",
      "Sharon Elaine Giftos is assigned to the terminal care ward Lynn Brioni Farrell to public health\n",
      "administration Priscilla Barbara Leigh to gynecology and Phred Karen Carlson to psychiatry These\n",
      "four beauties have ample opportunities to disrobe and fornicate of which they take advantage much to\n",
      "the delight of male viewers These are liberated women at the height of the sexual revolution after\n",
      "all and are as intelligent as they are horny and beautiful Visceral yet lowbudget action sequences\n",
      "are interspersed throughout Theres a very bloody gunfight at the resistance movement headquarters in\n",
      "which two policemen are shot and killed along with several members of the group An antiVietnam war\n",
      "protest consisting of spookilydressed young people of all races painted like skeletons becomes\n",
      "violent with cops beating protesters The effective trip sequence on the beach consists of beautiful\n",
      "weird and confusing sensory and memory montages with hypersensual overtones In short THE STUDENT\n",
      "NURSES is a thoughtful and compelling reflection of the times expressed through real womens\n",
      "perspectives since it was written and directed by a woman But its still fun and titillating despite\n",
      "its sobering treatment of subject matter\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: This is a case of taking a fairy tale too far The Enchanted Cottage delivers Dorothy McGuire\n",
      "as a terrible ugly spinster and Robert Young as a disfigured pilot Long story short Scarface marries\n",
      "Spinster after which their love transforms them miraculously lighting cosmetics and the removal of\n",
      "fake scars into beautiful peoplea magical change that they attribute to the enchantment of living in\n",
      "a seaside cottage that has been the abode of generations of honeymoonersIf the story stopped there\n",
      "fine it would be a fable with a proverbial message beauty is in the eye of the beholder But it\n",
      "lurches ahead reaching for reality When Mr and Mrs Scarface greet their public it comes as a painful\n",
      "shock to them that theyre still homely You see they only appear beautiful to each other a situation\n",
      "which the audience is well prepared for because all the secondary characters have been sermonizing\n",
      "that illfavored people really need to lower their expectations and find other ways to be happy You\n",
      "know Take up hobbies Spinster does woodcuts for instance Scarface considers collecting driftwoodThe\n",
      "original playwright Arthur Wing Pinero and the filmmakers have zero faith in human nature Their\n",
      "message is Youre either ugly or pretty and no pretty person would ever love an ugly one Whats even\n",
      "worse ugly people evidently need to imagine their lover as pretty Reality just wont doOne wonders\n",
      "what Elaine Mason saw every day when she looked at her husband Stephen Hawking\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This documentary on dinosaurs was undoubtedly fascinating and very well made However I found\n",
      "myself watching many of the bits with unease The film generally took a rather confident stand on\n",
      "anything it said and showed but inevitably much of the behaviour of the beasts their interaction\n",
      "with each other what they looked like how they moved what they ate etc much of that is surely\n",
      "guessing sometimes guessing with reasonable confidence sometimes just wild guessing But the viewer\n",
      "is never made aware of that the film pretends to actually observe real dinosaurs and their real\n",
      "behaviour etc That makes probably better viewing than confronting the audience with mountains of\n",
      "disclaimers but it makes it just a bit too populist in my estimation\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This is a great TV movie with a good story and many comic moments thanks to the excellent\n",
      "castThe only problem this movie has is that it hasnt stood the test of time as well as it might\n",
      "haveDespite this its definitely worth viewing particularly if you are an Alan Alda or Ruth Gordon\n",
      "fan\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: I dont care what anyone says this movie is hilarious It combines the bleak seriousness of\n",
      "Threads with an anarchic blend of alternative comedy and the results are a severely dark but\n",
      "outrageously funny satire on the brinkmanship policies of both the Western and Eastern blocs at the\n",
      "time You gotta give the filmmakers credit for even attempting to top the real life lunacy of Duck\n",
      "and cover or Protect and surviveImagine someone made a movie based on the Dead Kennedys track Kinky\n",
      "Sex Makes The World Go Round and youre pretty close to Whoops Apocalypse Add Rik Mayall on top form\n",
      "as an insanely OTT SAS commander and youve got it exactly A worthy companion piece to Dr Strangelove\n",
      "and thats saying something\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Given Christopher Nolans string of successful films its a no brainer for me to want to check\n",
      "out his filmography watch his debut feature which is shot in black and white back in England running\n",
      "less than 70 minutes long done with little budget but containing all the hallmarks that has made him\n",
      "a master filmmaker and storytellerThough short the film is no less gripping with its meandering plot\n",
      "that will leave you guessing because the premise doesnt even scratch the surface of this tale which\n",
      "is pretty amazing considering the depth in the narratives structure and characterization As told we\n",
      "follow a writer wannabe called Bill Jeremy Theobald who starts a habitual obsession with following\n",
      "random people he fancies on the streets in a voyeuristic manner which at first could be conceived as\n",
      "research before he starts to make up his own rules and break themHe meets up with charismatic Cobb\n",
      "Alex Haw who turns out to be a robber with peculiar sensibilities and modus operandi and soon finds\n",
      "himself hooked with hanging out with him as they go about breaking and entering and speculating\n",
      "about their victims livelihood as does the pursuit of a femme fatale blond Lucy Russell a mobsters\n",
      "moll who rejects his every advanceTold in a nonlinear fashion which comes with scenes that dont\n",
      "quite add up in the beginning this sets the film up for multiple viewings as you study just how\n",
      "Nolan sustains that suspense and intrigue with you as the audience expecting and wanting more which\n",
      "gets duly delivered There are enough twists here which spins the film into a dizzying crescendo\n",
      "where loose ends begin to come together and the brilliance of the stellar story start to shine\n",
      "throughIts also amazing how as a first feature shot on the cheap that something that clever and\n",
      "sophisticated can be conceived from his own experience in being burgled with Nolan involved in every\n",
      "stage of production from writing to shooting producing and directing having worked on the project\n",
      "for a year since shoots can only happen on weekends I guess heres an example of a successful\n",
      "filmmakers humble roots which should serve as inspiration and spur new filmmakers out there Now Ill\n",
      "patiently wait for Christopher Nolans Inception due out later this year whose trailer is already\n",
      "such a tease\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: I hadnt heard of Soap Girl but I saw a poster with a five star review from Film Threat\n",
      "outside the theater so I figured how bad could it be Well I soon found out My god this film was\n",
      "awful The most wooden acting I have ever seen outside of a porn flick Absolutely agonizing dialogue\n",
      "I just cant understand how this was made and why anyone agreed to be a part of it And I find it\n",
      "completely unfathomable that this was actually being shown in a theater and money was being charged\n",
      "to see it How did this happen And most importantly WHAT THE WAS THE GUY FROM FILM THREAT THINKING\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: I saw Ray when it first came out Why Partly because of the advertising hype secondly because\n",
      "I just loved the heck outa Ray Charless music But not being around when his biggest things in music\n",
      "and his life happened I wanted to learn more about the mans life And in this film I did His\n",
      "addiction to drugs was something I didnt know and the film let us knowBut heres the thing while this\n",
      "was a decent autobiographical filmI cannot say it was a great film Ive seen Malcolm X and was blown\n",
      "away Same with Whats Love Got To Do With It and Bird The performances of each of those films was\n",
      "outstanding I wasnt just drawn into the main characters in those films who did incredible jobs but\n",
      "to those around them as well That helps make a picture to meI felt that at some parts of this film\n",
      "was shallow and heavy handed for emotional appeal And yes Ill admit at certain parts of the film I\n",
      "almost fell asleep And the film was too long And the film left out several other important details\n",
      "of Ray Charles life that would have made the film flow better The film got choppy to me in certain\n",
      "parts And the film seemed to end with a whimper not a bang certain parts including the ending played\n",
      "like a tacked on Lifetime cable network movie to me I expect more outa cinemaSo where does my\n",
      "ambivalence come in With Jamie Foxxs performance Overall he did okay Not Denzel Washingtons Malcolm\n",
      "X or Angela Bassetts Tina Turners spectacular butokaySorry folks but to me there were several points\n",
      "in the film where I saw Jamie Foxxs interpretation of Ray Charles and in others thanks to the\n",
      "wonderful camera angles and lighting he looked like Ray Charles But I paid attention to the acting\n",
      "An actor has to make you believe he IS the character he is playing Not make a caricature of the\n",
      "character Did I believe Jamie Foxx was Ray on the screen Sometimes yes sometimes noDid Jamie Foxx\n",
      "deserve a Golden Globe You betcha Does he deserve an Oscar Depends on whos hes up against Hes got a\n",
      "few major competitors there and he might just edge them out But then againmaybe not If Jamie Foxx\n",
      "doesnt win I will not stand up and say he was robbed I wont particularly feel that he had beenThis\n",
      "was a decent film with decent performances and a decent story A great auto\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: NBC had a chance to make a powerful religious epic along the lines of The Ten Commandments\n",
      "and The Greatest Story Ever Told and instead they chose to make some halfhearted cartoon that was\n",
      "more like Waterworld than anything else I dont recall a Bible passage where Lot turns into a pirate\n",
      "and attacks the ark nor do I remember one where Noahs son develops a serious friendship with an\n",
      "orange nor do I remember Noah being some crazy old loon who suddenly acts like hes commanding a\n",
      "naval fleet and runs around shouting nautical terms like hoist the mainstay This was possibly the\n",
      "worst marketing decision in history Obviously the majority of people watching this were going to be\n",
      "Jewish and Christian parents with their kids so why on earth make the movie so offensive to those\n",
      "people If they were intentionally trying to offend why not advertise it that way and at least reel\n",
      "in the right audience I hope they make a REAL Noah movie someday one done seriously and thoughtfully\n",
      "one that actually appeals to people and makes money Until then dont waste your time with this trash\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Sometimes Hallmark can get it right like The 10th Kingdom but many of their fantasy films\n",
      "plod and this falls into the latter category The version I saw may have been cut a demon shown in\n",
      "the trailer and publicity stills didnt appear but anything that made the movie shorter can only be a\n",
      "blessingPOSSIBLE SPOILERS IF YOU ARE UNFAMILIAR WITH THE ORIGINAL FAIRY TALEAnyway the film updates\n",
      "the story to the early part of the 20th Century and makes Gerda and Kay here called Kai being a Lexx\n",
      "fan I kept expecting him to say The Dead do not solve puzzles 18 year olds Hans Christian Andersens\n",
      "basic story is followed the boy gets a shard of ice in his eye goes bad is taken off by the Snow\n",
      "Queen to solve a puzzle in her palace and Gerda goes to find him having various adventures on the\n",
      "wayAs the two main characters are older than in the original a lot of time is spent getting them\n",
      "together and in love Unfortunately I was never convinced that they were particularly in love and\n",
      "certainly not enough in love to make sense of Gerdas quest By the time the main plot kicks in the\n",
      "movies pace has slowed to a crawl Alas when Gerda begins her search for Kai it only manages to pick\n",
      "up the pace to a leisurely strollThere are a few odd additions to the story that seem to go nowhere\n",
      "At the start of the film the Snow Queen kills Gerdas mother but no explanation for this is given A\n",
      "polar bear living in the Snow Queens palace is more than he seems though this is possibly because\n",
      "the producers realised that the bears feelings towards the Snow Queen would be OK in a Fairy Tale\n",
      "but not in a modern film Again this is never explained Also hints that the Snow Queen has an erotic\n",
      "desire for Kai are dropped but never followed through The script is also full of anachronisms that\n",
      "really jar you out of the fairy tale moodThe production looks good though there is evidence of\n",
      "pennypinching the Snow Queens palace is the hotel where Gerda and Kai lived covered in ice The three\n",
      "main characters are played with varying degrees of success Kai comes across as bland as does Gerda\n",
      "initially but once she sets off to find Kai you warm to her Bridget Fonda looks great as the Snow\n",
      "Queen\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: OK OK I must say I was impressed Its hard to say what Im more impressed with my ability to\n",
      "choose the right romantic comedy to watch so that I dont gouge my eyes out or the movie itself\n",
      "Either way Hitch was pretty darn good Hey it was good enough for me to watch twice Will Smith was\n",
      "funny and good Kevin James was just hilarious and absolutely essential for the movie As much as this\n",
      "movie centered around Hitch Will Smith without Kevin James its just not the sameThe story is Hitch\n",
      "is a match maker that helps the guy woo the girl His job is to create the chance for the girl to\n",
      "notice the guy when she otherwise wouldnt After the encounter the rest is all up to the guy to make\n",
      "or break the relationship He works on referral only and stays largely unnoticed during the process\n",
      "Albert Kevin James is Hitchs project this time around and Albert has eyes on Allegra Cole Amber\n",
      "Valleta a Paris Hilton type figure While that plot unfolds Hitch himself has eyes on Sara Eva Mendes\n",
      "a sharp independent fanged gossip columnist that wants nothing to do with a relationshipThe two\n",
      "stories make for some funny moments and they tie together for a bit of a quagmire Of course no love\n",
      "story is complete without the obligatory miscommunication misunderstanding or mishap to send the guy\n",
      "chasing after the girl Fortunately they make it brief and unsappy Hitch was a fun and funny movie\n",
      "that flowed very well and rolled along without a hitch\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: What a silly movie While it looks nice it doesnt make a lot of sense On the one hand the\n",
      "film suggests that Juanas madness was that she was just a woman ahead of her time On the other hand\n",
      "she has an obsession that is right out of the worst Victorian novel of the wronged woman and that\n",
      "does seem a sort of mental problem like Miss Havesham in a castle This movie is what Elizabeth would\n",
      "have been if Elizabeth had not been able to get past Essexs sexual attraction\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This is a tough film to review since several factors need to be taken into account Lets\n",
      "filter the more judgmentalOk are you interested in the facts concerning the serial killer of Jeffrey\n",
      "Dahmer Can you withstand an independent lowbudget film Are you objective enough to NOT dislike a\n",
      "film solely due to its lack of stars or professional look Well if you said yes then you should have\n",
      "a mind open enough to handle this one This film is an almost 100% accurate dramatization of Dahmers\n",
      "adult life and subsequent murder spree and is styled as an autobiography It isnt a glamorized\n",
      "unrealistic account that unfortunately the theatrical film Dahmer 2001 was The movie begins with\n",
      "Dahmer played quite convincingly by Carl Crew sitting in the police car as they raid his apartment\n",
      "His thoughts of what got him there are presented to us in a pasttense narrated style that accurately\n",
      "explains much of Dahmers psychoses and motives which led him to commit murder almost 20 times We get\n",
      "to know the character both the devious side as well as the side that came moderately close to living\n",
      "a normal life It isnt anyones fault but Dahmers that 17 people died but being a criminal psychology\n",
      "student I was pleased to more than just his animalistic side represented truthfully in this film You\n",
      "see him having a loving relationship with his grandmother as well as trying to find companionship\n",
      "but of course we witness the side of him that everyone remembers It should be noted that there is\n",
      "little actual onscreen violence with much of it suggestive in shots such as spattering of blood or a\n",
      "body being struck through a blurred curtain You do see two deaths that I remember one being a pretty\n",
      "bloodless throat slash and the other being a man shoved alive into a barrel of acid While you dont\n",
      "see anything graphic this cruelty and the convincing acting of both Crew and his victim make this a\n",
      "disturbing scene And while the actual onscreen mutilation is kept low you will see the results There\n",
      "is a prop hand and head or two but it seems as if this was to disturb the viewer and doesnt look to\n",
      "be exploitive Besides these fake anatomical pieces are where the budget limitations are visible\n",
      "Although acceptable they look enough like fakes to not be too disturbing The film actually concludes\n",
      "before Dahmers death in 1994 due to the fact that it was released a year or two prior\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: I went into this movie with an open mind I had been too lazy to go to the video store to\n",
      "pick out a movie and my friend returned with this I promised him I wouldnt laugh at his choice but\n",
      "within the first five minutes I told him I would have to take back my promise We kept watching just\n",
      "hoping it would get better but no a continual mindrape followedThis movie was probably one of the\n",
      "worse ever committed to film and surely deserves a place on the IMDb Bottom 100 I really dont know\n",
      "how this got distributed The lighting was poor I have seen better acting in elementary school plays\n",
      "There is really nothing positive to say about it\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: First of all let me start by saying that I have been a devoted follower of C Thomas Howells\n",
      "career ever since The Outsiders and The Hitcher He was an up and coming star in the 1980s with hits\n",
      "such as Soul Man also The future was bright for this young actor and he had the potential to go on\n",
      "from there and really assert himself in Hollywood Put it this way Tom Cruise had a bit part in The\n",
      "Outsiders while Howell had the lead Look at Cruise today But picking material like this drivel will\n",
      "only denigrate Howells career even more if that was possible Why does he pick stuff like this A\n",
      "small part in a major movie would be of more benefit to him than this rubbishEssentially the story\n",
      "here takes place in a postapocalyptic world where everybody lives underground where chaos reigns\n",
      "Howell is a Shepherd protecting the flock of various religious leaders by killing off any\n",
      "undesirables Hes a hitman in other wordsThe sets are so bad they wouldnt look out of place on a\n",
      "Thunderbirds episode The use of slowmotion needlessly repeats itself throughout the movie but is\n",
      "well backed up by bad acting and bad is a kind word here no continuity scenes that are thrown in for\n",
      "no reason whatsoever vehicles that looked like they were made from a Corn Flakes box and a\n",
      "directorial style that bordered on stupidity Oh yeah and the storyline was pathetic tooI hate\n",
      "writing bad reviews about films especially those in which I really like the star but this film is so\n",
      "bad I dont believe for one second that anyone could have been proud of it I am not a filmmaker nor\n",
      "am I a director but I would hide my head in the sand if Id spent whatever amount of money and time\n",
      "on this movieIn short this was a monumental waste of time and energy and I would not recommend\n",
      "anyone to EVER see this film It came free with a DVD player I bought but I still turned the thing\n",
      "off halfway through because I was embarrassed for Howell Come on C give yourself some credit and\n",
      "wrestle yourself away from these nonhit wonders and try to knuckle down and get a good part however\n",
      "small110 and only because there is no setting for 010\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: First of all I personally adore Demons and Demons 2 I saw them although it was hard to find\n",
      "good horrors without good official movie distributing here in Russia when I was a kid and that is an\n",
      "unchangeable part of my boyhood Then I heard nothing about Mr Bava Then I saw his Ghost Son Well it\n",
      "is certainly not a good coming back Why was the leading character whom we never really knew to at\n",
      "least like him in accident in the middle of an empty road Why do African servants say so dumb and\n",
      "stupid things about human soul Why is the plot so primitive Havent we seen enough ghosts for 100\n",
      "years of movie production It is clear that Lamberto Bava has nothing to show us so far It is a shame\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: It may be a little creaky now and it certainly can never have the impact it once had but\n",
      "this is still a thrilling reminder of what Michael Jackson could once do Looking back on it now for\n",
      "the first time since its initial prominence I was struck not by the horror trappings quaint but fun\n",
      "and Vincent Price has never sounded so genuinely uncamply sic menacing than its absorption of the\n",
      "horror film allowing Jackson behind genre and makeup to give us a bravely revealing portrait of male\n",
      "sexualityBecause THRILLER isnt really about horror in the way horror isnt really about horror it is\n",
      "about that ageold theme the sexual awakening of a young woman The film opens in a cinema with\n",
      "Jacksons girlfriend uncomfortable with the imagery and the aggressively gendered response Of course\n",
      "she is on a date and she is less scared by the film than what she knows will be expected by her\n",
      "boyfriendThe mainstream imagery of the film they watch the group atmosphere all suggest the socially\n",
      "conditioned expectations This leads her not only to think of the body in disgust hence all the\n",
      "decaying ghouls the loss of her virginity is seen as a kind of death but the sexual rite is not just\n",
      "about her boyfriend but her peers her society hence its visualisation as a gang violationThis is\n",
      "brilliant disturbing stuff the best thing director Landis has ever done Jackson the most popular\n",
      "artist on the planet was still willing to show that the fixed image of a star contained multitudes\n",
      "not all of them reassuring The song itself has held up remarkably well the creepy insistent bass\n",
      "rhythms the extraordinarily salacious lyrics the beautiful 70s disco ecstasy tailing the chorus\n",
      "shattering timelessness revealing the milky desire behind the fear\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Telly Savalas hams it up as the Mexican revolutionary though hes matched by Chuck Connors as\n",
      "a military martinet in this jokey yet rather boring pastiche on the famous historical figures life\n",
      "and times An earlier attempt VILLA RIDES 1968 with Yul Brynner in the role and costarring Robert\n",
      "Mitchcum dealt with these events more soberly and on a grander scale As such PANCHO VILLA is an\n",
      "alltoo typical European venture and an undistinguished one at that despite its credentials the end\n",
      "result is more often silly rather than amusing though a few moments most notably the action\n",
      "setpieces and a scene involving a brawl inside a church offer some mild pleasure Oh and Savalas even\n",
      "gets to sing over the end titles\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This film could of been a hell of a lot better if they didnt use Brian Conley as a gangster\n",
      "and if they didnt start the film with Christopher BigginsWhen I watched this film I had absolutely\n",
      "no idea what was going on There were too many double crosses and plot twists to make the film\n",
      "believable The film deserves a 0 but seeing as I there isnt a 0 I gave it a 1I wouldnt recommend\n",
      "this film to my worst enemy I would rather poke out my eyeballs with some rusty scissors than watch\n",
      "this film again Im telling you that was an hour and a half of my life I wont get backIf you want to\n",
      "watch a gangster film dont get this Watch Going Off Big Time or Lock Stock and Two Smoking Barrels\n",
      "instead\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Few people realize it but there was world literature in the ancient world before the Greeks\n",
      "came on the scene Besides the literary remains that are in the Old Testament of the Jews there were\n",
      "considerable works from Mesopotamia and Egypt The summit of the former were the religious poetry and\n",
      "The Epic Of Gilgamesh The Egyptians produced many poems but there main addition was a tale of\n",
      "adventure of a traveler and physician called The Story Of Sinuhe It is from this work actually a\n",
      "fragment that we dont know the ending of that the novel The Egyptian came fromThe story is unique as\n",
      "is the movie The Egyptian was a best seller in the early 1950s and Darryl Zanuck decided to take a\n",
      "chance making it yes he wanted a showcase for his girlfriend Bella Darvi as Nefer as well as the\n",
      "rest of the cast Victor Mature Edmund Purdom Peter Ustinov Michael Wilding and Gene Tierney but he\n",
      "was aware that these films rarely made large box office One can chalk up this as an example of\n",
      "Zanuck trying something differentThe number of movies that deal with ancient Egypt are very small\n",
      "Land Of The Pharoahs The Egyptian The Ten Commandments both De Mille versions Moses Holy Moses\n",
      "Cleopatra The Mummy all versions The Scorpion King If there are 20 films about ancient Egypt its is\n",
      "tremendous But The Egyptian is unique While the second Ten Commandments discusses Ramses the Great\n",
      "Pharoah Ramses II Yul Brynner and his father Seti I Cedric Hardwicke and the films on Cleopatra deal\n",
      "with her few other names of ancient Egypt crop up in film Egypts greatest Pharoah was Thutmose III\n",
      "who conquered most of the known middle east of the era of 1470 BCE or so No film about him has\n",
      "appeared nor of his usurping predecessor historys first great female ruler Hatschepsut But the only\n",
      "known Pharoah who attempted a religious revolution that approached what the Jews and later the\n",
      "Christians attempted a type of monotheism is the subject of The Egyptian This is Pharoah AkhnatonIn\n",
      "reality Akhnaton was practicing a personal form of monotheism that was not meant for public\n",
      "consumption But it angered the priestly class who worshiped Amon rather than Aton Due to our\n",
      "uncertain historic records although Ak\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: The film opens with the director talking to the camera and saying he is going to show a\n",
      "story about Brazilain street kids whose families live in poverty and must steal and kill to survive\n",
      "In fact the main character Pixote was played by an actual street kid only 11 years old What follows\n",
      "was one of the most brutal depressing and horrifying film Ive even seen I saw it about 17 years ago\n",
      "on a double bill with Black Orpheus and have never forgotten it I dont think I ever want to see it\n",
      "againit was just too much SPOILER AHEAD The scene which will not leave me is when Pixote meets a\n",
      "prostitute who has to abort her own fetus You dont see her do itbut you get a quick glance at what\n",
      "she got out Its almost 20 years later and just recalling that scene upsets me SPOILER ENDThe movie\n",
      "gets more brutal as it goes along and ends the only way it can Whats all the more harrowing is\n",
      "stories like this really did happen in Brazil in 1981and are STILL happening todayA harrowing brutal\n",
      "filmbut it should be seen if you can handle it Im surprised this got an R ratingIve seen X rated\n",
      "film that are less graphic A 10\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Nothing really unpredictable in this movie but a solid flick in all respects Everything from\n",
      "acting to cinematography was solid Not a perfectly linear plot line but there wasnt anything you\n",
      "couldnt see coming Perhaps a tad melodramatic at points but again a fairly decent movie none the\n",
      "less Definitely worth checking out If in doubt of what film to rent over the weekend give this a go\n",
      "Though you may not feel like running out and buying it I found it to be quite worth while\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: It is a shame that this series hasnt been remastered and produced on video by Warner or some\n",
      "other professional movie houseCopies of most episodes are available but are usually of poor quality\n",
      "being copies of copies of copiesAs I understand it 92 episodes were produced during its run but only\n",
      "15 are noted hereSome of the series writers such as Richard Matheson went on to become noted\n",
      "authorsExcellent series well written well staged and well producedMichael WeldonUdon Thani Thailand\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: I have so much hope for the sequel to GenX Luckily my hopes have came true You got a whole\n",
      "bunch of action comedysilly comedy and surprises I think the newcomer Edison is really a hit in the\n",
      "movie but I really find Sams Alien stupidly annoying with English Although the movie had some flaws\n",
      "with the robot graphics and the silly dialogue the action always keeps it strong The action setup is\n",
      "much stronger than the 1stThis movie is getting more of an American feel since 60% of the movie is\n",
      "in English from the Cantonese This movie will not disappoint you I recommended this for young uns\n",
      "that care about pure actionpacked fun\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: This show had a promising start as sort of the opposite of Oceans 11 but has developed into\n",
      "a shallow display of T & A Actually according to my little brother thats the only good part of the\n",
      "show The first season was by far the best it was new and interesting things just went downhill after\n",
      "that The only redeeming point of this show is JamesCaan The other actors are lackluster The\n",
      "characters lack depth and they seem to be incredibly selfish nd generally unlikable people To quote\n",
      "a friend Las Vegas is like Baywaych in a Casino In my opinion thats way to generous Baywatch was way\n",
      "better and much more realistic\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Hey you are not alone I remember Nichols I was just 17 when it was on I remember James\n",
      "Garner was one of the coolest actors and Nichols was such a great show I couldnt believe it was on\n",
      "such a short time wish I could remember the last episode I probably didnt see itthere were no vcrs\n",
      "back then so it when it was on you saw it and if you missed an episode it was gone forever unless it\n",
      "came back on summer reruns Anyway sure would be great if it came out on DVD but I dont think that\n",
      "many people even knew about it What a shameGarner would hit it big a few years later with Rockford\n",
      "Files and he brought along his buddy Stuart Margolin from Nichols to play his sidekick Angel\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Oh my god Obviously when you rent or buy this youre not expecting to see a documentary on\n",
      "the mating habits of small rodents in their natural habitats Youre expecting a visual feast of blood\n",
      "and gore and and maybe even a scare or two well for those who are as sick and twisted as myself you\n",
      "wont find many scares but youll come very close to urinating all over yourself in laughter the catch\n",
      "phrases in this movie will stay with you and your friends forever The first time i showed this to my\n",
      "friends and colleagues was over 3 years ago but still we laugh our asses off and use the catch\n",
      "phrases its as addictive and funny as Sam Raimis The Evil Dead II Dead By Dawn and Peter Jacksons\n",
      "Dead AliveBraindead From the opening scenes absolutely ridiculous dialog to the Splatter and Gore\n",
      "Departments finest works to the wondrous abilities of Ed the film cutter you will laugh and laugh\n",
      "again As far as the visual feast of blood and gore oh yeah theyve got it And theyre pretty damn good\n",
      "at it The neckbones connected to the headbone This film also may have done the best\n",
      "nightmarehallucinationtotally effing nuts scene i have ever seen and that ones not mean to be funny\n",
      "but man is it well done and creepy Overall to anyone who is not against a bunch of blood and a damn\n",
      "good time IF YOU EVER SEE THIS MOVIE GET IT its on Netflix i know that for sure\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual sentiment: %s\" % targets[i])\n",
    "    print(\"Predicted sentiment: %s\" % dec[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbaa43d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7862be76f0d345d38e83567e3ff1f307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, num_workers=4, shuffle=True)\n",
    "model.model.eval()\n",
    "outputs = []\n",
    "targets = []\n",
    "cudamodel = model.model.to('cuda')\n",
    "for batch in tqdm(loader):\n",
    "  outs = cudamodel.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=11)\n",
    " \n",
    "  dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
    "  target = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch[\"target_ids\"]]\n",
    "  \n",
    "  outputs.extend(dec)\n",
    "  targets.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df9477ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92      3130\n",
      "    positive       0.96      0.88      0.92      3118\n",
      "\n",
      "    accuracy                           0.92      6248\n",
      "   macro avg       0.92      0.92      0.92      6248\n",
      "weighted avg       0.92      0.92      0.92      6248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(targets, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbbda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chi2022] *",
   "language": "python",
   "name": "conda-env-chi2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
