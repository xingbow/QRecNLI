{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fef2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(os.path.dirname(os.getcwd()), 'backend')\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_number = 42\n",
    "set_seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc684dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GV.SPIDER_FOLDER: /data2/xingbo/chi2022/seqNLI/backend/app/dataService/../data/dataset/spider\n"
     ]
    }
   ],
   "source": [
    "from app.dataService import globalVariable as GV\n",
    "# from app.dataService.dataService import DataService\n",
    "print(f\"GV.SPIDER_FOLDER: {GV.SPIDER_FOLDER}\")\n",
    "from app.dataService.utils.processSQL import process_sql\n",
    "from app.dataService.utils.processSQL import decode_sql\n",
    "from app.dataService import sql2sql\n",
    "\n",
    "db_schema, db_names, tables = process_sql.get_schemas_from_json(os.path.join(GV.SPIDER_FOLDER, \"tables.json\"))\n",
    "# dataService = DataService(\"spider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dd62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = \"query_seq\"\n",
    "f_type = \"train\"\n",
    "# f_name = \"query_seq_1\"\n",
    "# f_type = \"dev\"\n",
    "with open(os.path.join(GV.SPIDER_FOLDER , f\"{f_name}.json\"), \"r\") as f:\n",
    "    seq_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660aac24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sources):  5170 5170 5170\n",
      "['activity: activity name']\n"
     ]
    }
   ],
   "source": [
    "# convert sequences to pairwise pairs\n",
    "def extract_select_ent(select):\n",
    "    cols_ents = []\n",
    "    for s in select[1]:\n",
    "        agg_id = s[0]\n",
    "        val_unit = s[1]\n",
    "        # 'select': (isDistinct(bool), [(agg_id, val_unit), (agg_id, val_unit), ...])\n",
    "        # val_unit: (unit_op, col_unit1, col_unit2)\n",
    "        # col_unit: (agg_id, col_id, isDistinct(bool))\n",
    "        unit_op, col_unit1, col_unit2 = val_unit\n",
    "        agg_id1, col1, isDistinct1 = col_unit1\n",
    "        \n",
    "        cols = col1\n",
    "        if col_unit2 is not None:\n",
    "            agg_id2, col2, isDistinct2 = col_unit2\n",
    "            cols += \", \" + col2\n",
    "        cols_ents.append(cols)\n",
    "    \n",
    "    # print(\"cols_ents: {}\".format(cols_ents))\n",
    "    return cols_ents\n",
    "\n",
    "def organize_meta(table):\n",
    "    table_names = table[\"table_names\"]\n",
    "    col_names = table[\"column_names\"]\n",
    "    meta = []\n",
    "    for table_id, table_name in enumerate(table_names):\n",
    "        t = table_name + \" (\" + \", \".join([col_name[1] for col_name in col_names if col_name[0] == table_id]) + \")\"\n",
    "        meta.append(t)\n",
    "    return meta\n",
    "\n",
    "sources = []\n",
    "targets = []\n",
    "metas = []\n",
    "for db_name in seq_data.keys():\n",
    "    # print(db_name, seq_data[db_name].keys())\n",
    "    sqlseqs = seq_data[db_name][\"sql\"]\n",
    "    for sqlseq in sqlseqs:\n",
    "        for sqlid, sql in enumerate(sqlseq):\n",
    "            schema = process_sql.Schema(db_schema[db_name], tables[db_name])\n",
    "            sql_label = process_sql.get_sql(schema, sql)\n",
    "            select_decoded = decode_sql.decode_select(sql_label, tables[db_name])\n",
    "            curr_select_ents = extract_select_ent(select_decoded)\n",
    "            meta = organize_meta(tables[db_name])\n",
    "            if sqlid + 1 < len(sqlseq):\n",
    "                sql_next_label = process_sql.get_sql(schema, sqlseq[sqlid + 1])\n",
    "                next_select_decoded = decode_sql.decode_select(sql_next_label, tables[db_name])\n",
    "                next_select_ents = extract_select_ent(next_select_decoded)\n",
    "                # organize pairs\n",
    "                sources.append(curr_select_ents)\n",
    "                targets.append(next_select_ents)\n",
    "                metas.append(meta)\n",
    "                \n",
    "print(\"len(sources): \", len(sources), len(targets), len(metas))\n",
    "\n",
    "print(sources[0])\n",
    "\n",
    "# with open(os.path.join(GV.SPIDER_FOLDER ,f\"{f_name}_{f_type}.json\"), \"w\") as f:\n",
    "#     json.dump({\n",
    "#         \"meta\": metas,\n",
    "#         \"source\": sources,\n",
    "#         \"target\": targets\n",
    "#     }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de8ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(GV.SPIDER_FOLDER ,f\"{f_name}_{f_type}.json\"), \"r\") as f:\n",
    "    pairs_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a0302c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['meta', 'source', 'target'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb23a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082b509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.sources): 5170\n"
     ]
    }
   ],
   "source": [
    "dataset = sql2sql.get_spider_dataset(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36b3ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.targets[0]: {'input_ids': tensor([[1756,   10, 1429,    1,    1,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset.targets[0]: {dataset.targets[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cebd230",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca474bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p t5_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3168276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = sql2sql.args_dict\n",
    "args_dict.update({'output_dir': 't5_seq', 'num_train_epochs': 10, 'vocab_file': 'tokenizer_config.json'})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da30518b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = sql2sql.T5FineTuner(args)\n",
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f6b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.sources): 5170\n",
      "len(self.sources): 5170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebf372254884467b7a06e2b613e0767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingbo/anaconda3/envs/chi2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:398: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the model this way so next time you can load it using T5ForConditionalGeneration.from_pretrained\n",
    "model.model.save_pretrained('t5_seq')\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "241acf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "it = iter(loader)\n",
    "batch = next(it)\n",
    "batch[\"source_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c411d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudamodel = model.model.to('cuda')\n",
    "outs = cudamodel.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "280bbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
    "sources = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['source_ids']]\n",
    "targets = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['target_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34300fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: mountain: name *, mountain (mountain id, name, height, prominence, range, country), climber\n",
      "(climber id, name, country, time, points, mountain id)\n",
      "\n",
      "Actual: climber: name, mountain: height\n",
      "Predicted: mountain: name\n",
      "=====================================================================\n",
      "\n",
      "Review: customer orders: actual delivery date *, reference payment methods (payment method code,\n",
      "payment method description), reference service types (service type code, parent service type code,\n",
      "service type description), addresses (address id, line 1, line 2, city town, state county, other\n",
      "details), products (product id, product name, product price, product description, other product\n",
      "service details), marketing regions (marketing region code, marketing region name, marketing region\n",
      "descriptrion, other details), clients (client id, address id, customer email address, customer name,\n",
      "customer phone, other details), drama workshop groups (workshop group id, address id, currency code,\n",
      "marketing region code, store name, store phone, store email address, other details), performers\n",
      "(performer id, address id, customer name, customer phone, customer email address, other details),\n",
      "customers (customer id, address id, customer name, customer phone, customer email address, other\n",
      "details), stores (store id, address id, marketing region code, store name, store phone, store email\n",
      "address, other details), bookings (booking id, customer id, workshop group id, status code, store\n",
      "id, order date, planned delivery date, actual delivery date, other order details), performers in\n",
      "bookings (order id, performer id), customer orders (order id, customer id, store id, order date,\n",
      "planned delivery date, actual delivery date, other order details), order items (order item id, order\n",
      "id, product id, order quantity, other item details), invoices (invoice id, order id, payment method\n",
      "code, product id, order quantity, other item details, order item id), services (service id, service\n",
      "type code, workshop group id, product description, product name, product price, other product\n",
      "service details), bookings services (order id, product id), invoice items (invoice item id, invoice\n",
      "id, order id, order item id, product id, order quantity, other item details)\n",
      "\n",
      "Actual: bookings: status code\n",
      "Predicted: drama workshop groups: store name\n",
      "=====================================================================\n",
      "\n",
      "Review: research outcomes: outcome description *, document types (document type code, document\n",
      "description), documents (document id, document type code, grant id, sent date, response received\n",
      "date, other details), grants (grant id, organisation id, grant amount, grant start date, grant end\n",
      "date, other details), organisation types (organisation type, organisation type description),\n",
      "organisations (organisation id, organisation type, organisation details), project outcomes (project\n",
      "id, outcome code, outcome details), project staff (staff id, project id, role code, date from, date\n",
      "to, other details), projects (project id, organisation id, project details), research outcomes\n",
      "(outcome code, outcome description), research staff (staff id, employer organisation id, staff\n",
      "details), staff roles (role code, role description), tasks (task id, project id, task details, eg\n",
      "agree objectives)\n",
      "\n",
      "Actual: research outcomes: outcome description\n",
      "Predicted: research outcomes: outcome description\n",
      "=====================================================================\n",
      "\n",
      "Review: financial transactions: transaction amount, financial transactions: transaction amount *,\n",
      "accounts (account id, customer id, account name, other account details), customers (customer id,\n",
      "customer first name, customer last name, customer address, customer phone, customer email, other\n",
      "customer details), customers cards (card id, customer id, card type code, card number, date valid\n",
      "from, date valid to, other card details), financial transactions (transaction id, previous\n",
      "transaction id, account id, card id, transaction type, transaction date, transaction amount,\n",
      "transaction comment, other transaction details)\n",
      "\n",
      "Actual: financial transactions: transaction amount, financial transactions: transaction amount\n",
      "Predicted: financial transactions: transaction amount\n",
      "=====================================================================\n",
      "\n",
      "Review: station: id, station: name *, station (id, name, latitude, longitude, dock count, city,\n",
      "installation date), status (station id, bikes available, docks available, time), trip (id, duration,\n",
      "start date, start station name, start station id, end date, end station name, end station id, bike\n",
      "id, subscription type, zip code), weather (date, max temperature f, mean temperature f, min\n",
      "temperature f, max dew point f, mean dew point f, min dew point f, max humidity, mean humidity, min\n",
      "humidity, max sea level pressure inches, mean sea level pressure inches, min sea level pressure\n",
      "inches, max visibility miles, mean visibility miles, min visibility miles, max wind speed mph, mean\n",
      "wind speed mph, max gust speed mph, precipitation inches, cloud cover, events, wind dir degrees, zip\n",
      "code)\n",
      "\n",
      "Actual: station: name, station: id\n",
      "Predicted: station: city\n",
      "=====================================================================\n",
      "\n",
      "Review: customer contact channels: channel code, customer contact channels: contact number *,\n",
      "addresses (address id, address content, city, zip postcode, state province county, country, other\n",
      "address details), products (product id, product details), customers (customer id, payment method,\n",
      "customer name, date became customer, other customer details), customer addresses (customer id,\n",
      "address id, date address from, address type, date address to), customer contact channels (customer\n",
      "id, channel code, active from date, active to date, contact number), customer orders (order id,\n",
      "customer id, order status, order date, order details), order items (order id, product id, order\n",
      "quantity)\n",
      "\n",
      "Actual: customers: customer name, customer contact channels: active from date\n",
      "Predicted: customer contact channels: channel code\n",
      "=====================================================================\n",
      "\n",
      "Review: city: city *, city (city id, city, hanzi, hanyu pinyin, regional population, gdp), match\n",
      "(match id, date, venue, score, result, competition), temperature (city id, jan, feb, mar, apr, jun,\n",
      "jul, aug, sep, oct, nov, dec), hosting city (year, match id, host city)\n",
      "\n",
      "Actual: city: city, city: gdp\n",
      "Predicted: city: city\n",
      "=====================================================================\n",
      "\n",
      "Review: branch: membership amount, branch: membership amount *, member (member id, card number,\n",
      "name, hometown, level), branch (branch id, name, open year, address road, city, membership amount),\n",
      "membership register branch (member id, branch id, register year), purchase (member id, branch id,\n",
      "year, total pounds)\n",
      "\n",
      "Actual: branch: membership amount, branch: membership amount\n",
      "Predicted: branch: membership amount\n",
      "=====================================================================\n",
      "\n",
      "Review: company: market value, company: market value, company: market value *, company (company id,\n",
      "rank, company, headquarters, main industry, sales billion, profits billion, assets billion, market\n",
      "value), gas station (station id, open year, location, manager name, vice manager name,\n",
      "representative name), station company (station id, company id, rank of the year)\n",
      "\n",
      "Actual: company: main industry, company: market value\n",
      "Predicted: company: main industry\n",
      "=====================================================================\n",
      "\n",
      "Review: cinema: location *, film (film id, rank in series, number in season, title, directed by,\n",
      "original air date, production code), cinema (cinema id, name, openning year, capacity, location),\n",
      "schedule (cinema id, film id, date, show times per day, price)\n",
      "\n",
      "Actual: cinema: name, schedule: show times per day\n",
      "Predicted: cinema: location\n",
      "=====================================================================\n",
      "\n",
      "Review: enzyme: name *, medicine (id, name, trade name, fda approved), enzyme (id, name, location,\n",
      "product, chromosome, omim, porphyria), medicine enzyme interaction (enzyme id, medicine id,\n",
      "interaction type)\n",
      "\n",
      "Actual: enzyme: name\n",
      "Predicted: medicine: name\n",
      "=====================================================================\n",
      "\n",
      "Review: roles: role name, roles: role description *, reference document types (document type code,\n",
      "document type name, document type description), reference calendar (calendar date, day number),\n",
      "reference locations (location code, location name, location description), roles (role code, role\n",
      "name, role description), all documents (document id, date stored, document type code, document name,\n",
      "document description, other details), employees (employee id, role code, employee name, gender mfu,\n",
      "date of birth, other details), document locations (document id, location code, date in location\n",
      "from, date in locaton to), documents to be destroyed (document id, destruction authorised by\n",
      "employee id, destroyed by employee id, planned destruction date, actual destruction date, other\n",
      "details)\n",
      "\n",
      "Actual: documents to be destroyed: destruction authorised by employee id, documents to be destroyed: *\n",
      "Predicted: roles: role name\n",
      "=====================================================================\n",
      "\n",
      "Review: market: * *, film (film id, title, studio, director, gross in dollar), market (market id,\n",
      "country, number cities), film market estimation (estimation id, low estimate, high estimate, film\n",
      "id, type, market id, year)\n",
      "\n",
      "Actual: market: *\n",
      "Predicted: film: studio\n",
      "=====================================================================\n",
      "\n",
      "Review: person friend: friend *, person (name, age, city, gender, job), person friend (name, friend,\n",
      "year)\n",
      "\n",
      "Actual: person friend: name\n",
      "Predicted: person: friend\n",
      "=====================================================================\n",
      "\n",
      "Review: film: studio *, film (film id, title, studio, director, gross in dollar), market (market id,\n",
      "country, number cities), film market estimation (estimation id, low estimate, high estimate, film\n",
      "id, type, market id, year)\n",
      "\n",
      "Actual: film market estimation: low estimate, film market estimation: high estimate\n",
      "Predicted: film: studio\n",
      "=====================================================================\n",
      "\n",
      "Review: artwork: name *, festival detail (festival id, festival name, chair name, location, year,\n",
      "num of audience), artwork (artwork id, type, name), nomination (artwork id, festival id, result)\n",
      "\n",
      "Actual: artwork: type\n",
      "Predicted: artwork: name\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    lines = textwrap.wrap(\"Review:\\n%s\\n\" % sources[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual: %s\" % targets[i])\n",
    "    print(\"Predicted: %s\" % dec[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e57aeb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f742505e69c4f9cbc2aeafa1e46188b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, num_workers=4, shuffle=True)\n",
    "model.model.eval()\n",
    "outputs = []\n",
    "targets = []\n",
    "cudamodel = model.model.to('cuda')\n",
    "for batch in tqdm(loader):\n",
    "  outs = cudamodel.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=512)\n",
    " \n",
    "  dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
    "  target = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch[\"target_ids\"]]\n",
    "  \n",
    "  outputs.extend(dec)\n",
    "  targets.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd92384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-macro: 0.06327901523557042\n",
      "f1-micro: 0.19709864603481628\n"
     ]
    }
   ],
   "source": [
    "print(\"f1-macro: {}\".format(metrics.f1_score(targets, outputs, average='macro')))\n",
    "print(\"f1-micro: {}\".format(metrics.f1_score(targets, outputs, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ad35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chi2022] *",
   "language": "python",
   "name": "conda-env-chi2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
